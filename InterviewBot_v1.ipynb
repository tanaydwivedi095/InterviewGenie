{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Importing necessary libraries and functions, and defining Global Variables",
   "id": "91360d9e3f318a9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Importing Libraries and functions",
   "id": "b3240139e1d931a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:15.876887Z",
     "start_time": "2025-02-09T04:33:15.859242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import fitz\n",
    "from tqdm.autonotebook import tqdm\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "from spacy.lang.en import STOP_WORDS\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import util\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig"
   ],
   "id": "f39f377a70ef2e04",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Defining Global Variables",
   "id": "3f302fe437f39cc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:18.949585Z",
     "start_time": "2025-02-09T04:33:18.946848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# variable storing the path of the dataset(PDF) that is to be loaded for the RAG model to fetch the data from\n",
    "PDF_PATH = \"Dataset.pdf\"\n",
    "\n",
    "# variable storing value of the chunk i.e. the number of sentences to be clubbed together to form a paragraph in a page\n",
    "SENTENCE_CHUNK_SIZE = 5\n",
    "\n",
    "# variable storing the name of the model that will be used to embed the sentence chunks to numerical values\n",
    "EMBEDDING_MODEL = \"all-mpnet-base-v2\"\n",
    "\n",
    "# variable storing the query the is to be passed into the RAG model\n",
    "QUERY = \"What is a Binary Tree?\"\n",
    "\n",
    "# variable storing the value i.e. the number of top answers to fetch based on the highest similarity scores\n",
    "K = 3\n",
    "\n",
    "# variable storing the name of the LLM that will be used for the text generation\n",
    "LLM_MODEL_NAME = \"google/gemma-2b-it\""
   ],
   "id": "15601f1a7db20a01",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Data Acquisition",
   "id": "9ad7ebd0b67dff32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Removing Stop words",
   "id": "655090fef98a7f03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:21.375478Z",
     "start_time": "2025-02-09T04:33:21.357279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_stop_words(text: str) -> str:\n",
    "\n",
    "    '''\n",
    "    :param text:\n",
    "    :return:\n",
    "\n",
    "    This functions takes in a string and removes stop words from it.\n",
    "    The stop words are defined in the global variable STOP_WORDS imported from spacy.lang.en\n",
    "    '''\n",
    "\n",
    "    # Split the text by space into a list of words\n",
    "    text = text.split()\n",
    "\n",
    "    # Initialize a list for storing the non-stop words\n",
    "    cleaned_text = list()\n",
    "\n",
    "    # Iterate over the split text\n",
    "    for word in text:\n",
    "\n",
    "        # If the current word is not in stop words add it to the cleaned text list\n",
    "        if word not in STOP_WORDS:\n",
    "            cleaned_text.append(word)\n",
    "\n",
    "    # Return\n",
    "    return \" \".join(cleaned_text)"
   ],
   "id": "b6f3e9c789b08b30",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Converting the text to a desired format",
   "id": "a7dbaeb4882ba2c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:22.492642Z",
     "start_time": "2025-02-09T04:33:22.487417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_formatter(text: str) -> str:\n",
    "\n",
    "    '''\n",
    "    :param text:\n",
    "    :return:\n",
    "\n",
    "    The function takes in a string and formats according to the instructions provided\n",
    "    '''\n",
    "\n",
    "    # Instruction replacing newline character with space\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    # Instruction replacing dual spaces with single spaces\n",
    "    cleaned_text = cleaned_text.replace(\"  \", \" \")\n",
    "\n",
    "    # Instruction converting the whole text to lowercase text\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "\n",
    "    # Instruction replacing HTML comments with null string\n",
    "    cleaned_text = re.sub(r\"<!--.*?-->\", \"\", cleaned_text)\n",
    "\n",
    "    # Instruction replacing HTML tags with null string\n",
    "    cleaned_text = re.sub(r\"<.*?>\", \"\", cleaned_text)\n",
    "\n",
    "    # Instruction to remove the stop words from the text\n",
    "    cleaned_text = remove_stop_words(cleaned_text)\n",
    "\n",
    "    # Return\n",
    "    return cleaned_text"
   ],
   "id": "1e010ce4556f998d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Converting sentences to embedding vectors",
   "id": "f3e1bcc14998a4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:23.581156Z",
     "start_time": "2025-02-09T04:33:23.576471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sentence_embedder(sentences: list[str]) -> list[list[float]]:\n",
    "\n",
    "    '''\n",
    "    :param sentences:\n",
    "    :return:\n",
    "\n",
    "    This function takes in a list of sentence chunks and returns a list of embeddings for each sentence.\n",
    "    The model used for sentence embedding is defined in GLOBAL VARIABLES as EMBEDDING_MODEL.\n",
    "    The function iterates over the sentence chunks, then converts each sentence chunk to an embedding and returns a list of embeddings for each sentence.\n",
    "    '''\n",
    "\n",
    "    embedding_model = SentenceTransformer(model_name_or_path=EMBEDDING_MODEL)\n",
    "    embeddings = list()\n",
    "    for sentence in sentences:\n",
    "        embedding = embedding_model.encode(sentence,\n",
    "                                           batch_size=32,\n",
    "                                           convert_to_tensor=True,\n",
    "                                           show_progress_bar=True)\n",
    "        embedding = np.stack(embedding.tolist(), axis=0)\n",
    "        embedding = torch.tensor(embedding)\n",
    "        embedding = embedding.type(torch.float32)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings"
   ],
   "id": "56dd02e709788411",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Opening and Reading the PDF for the RAG model",
   "id": "827ccc8626cb3507"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:24.867299Z",
     "start_time": "2025-02-09T04:33:24.860803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    '''\n",
    "    :param pdf_path:\n",
    "    :return:\n",
    "\n",
    "    This function is used to open the pdf file and store it alongside its metadata in a list of dictionaries representing each page.\n",
    "    '''\n",
    "\n",
    "    # Open the PDF document\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    # List to store pages and their text data\n",
    "    pages_and_text = []\n",
    "\n",
    "    # Initialize spaCy model for sentence segmentation\n",
    "    nlp = English()\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "    # Iterate over each page in the document\n",
    "    for page_number, page in tqdm(enumerate(doc), total=len(doc)):\n",
    "        text = page.get_text()\n",
    "\n",
    "        # Format the text (Assuming `text_formatter` is defined elsewhere)\n",
    "        formatted_text = text_formatter(text)\n",
    "\n",
    "        # Split formatted text into sentences\n",
    "        sentences = list(nlp(formatted_text).sents)\n",
    "        sentences = [str(sentence) for sentence in sentences]\n",
    "\n",
    "        # Skip pages with 1 or fewer sentences\n",
    "        if len(sentences) <= 1:\n",
    "            continue\n",
    "\n",
    "        # Chunk sentences into groups (Assuming SENTENCE_CHUNK_SIZE is defined)\n",
    "        sentence_chunks = [sentences[i: i + SENTENCE_CHUNK_SIZE] for i in range(0, len(sentences), SENTENCE_CHUNK_SIZE)]\n",
    "        sentence_chunks = [\" \".join(chunk) for chunk in sentence_chunks]\n",
    "\n",
    "        # Generate embeddings for sentence chunks (Assuming `sentence_embedder` is defined)\n",
    "        sentence_embeddings = sentence_embedder(sentence_chunks)\n",
    "\n",
    "        # Ensure embeddings are NumPy arrays\n",
    "        sentence_embeddings = [np.array(emb) for emb in sentence_embeddings]\n",
    "\n",
    "        # Add page data to the list\n",
    "        pages_and_text.append({\n",
    "            \"page_number\": page_number + 1,\n",
    "            \"raw_text\": text,\n",
    "            \"formatted_text\": formatted_text,\n",
    "            \"number_of_sentences\": len(sentences),\n",
    "            \"number_of_words\": len(formatted_text.split()),\n",
    "            \"number_of_tokens\": len(formatted_text) / 4,  # Rough estimate\n",
    "            \"sentences\": sentences,\n",
    "            \"sentence_chunks\": sentence_chunks,\n",
    "            \"number_of_sentence_chunks\": len(sentence_chunks),\n",
    "            \"sentence_chunk_embeddings\": sentence_embeddings\n",
    "        })\n",
    "\n",
    "    return pages_and_text"
   ],
   "id": "96d81311fba5a165",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Fetch similarity",
   "id": "1aeeb610470a4908"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Fetching the embeddings of the data and converting them to a desired format of (number of documents, number of embeddings)",
   "id": "727c94a2aa306ff8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:27.061978Z",
     "start_time": "2025-02-09T04:33:27.057395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to extract embeddings and convert to PyTorch tensor\n",
    "def get_data_embeddings(pages_and_text: list[dict]) -> torch.Tensor:\n",
    "\n",
    "    '''\n",
    "    :param pages_and_text:\n",
    "    :return:\n",
    "\n",
    "    This function takes in a list of pages and returns a tensor of embeddings for each page.\n",
    "    '''\n",
    "\n",
    "    # List to store all embeddings\n",
    "    pages_and_text_embeddings = []\n",
    "\n",
    "    # Iterate through pages and collect sentence chunk embeddings\n",
    "    for page in tqdm(pages_and_text):\n",
    "        page_embeddings = []\n",
    "\n",
    "        for chunk_embedding in page[\"sentence_chunk_embeddings\"]:\n",
    "            # Convert to list if it's a tensor\n",
    "            if isinstance(chunk_embedding, torch.Tensor):\n",
    "                chunk_embedding = chunk_embedding.tolist()\n",
    "            page_embeddings.append(chunk_embedding)\n",
    "\n",
    "        # Append the page's embeddings\n",
    "        pages_and_text_embeddings.append(page_embeddings)\n",
    "\n",
    "    # Ensure all embeddings have the same dimension\n",
    "    if pages_and_text_embeddings:\n",
    "        embedding_dim = len(pages_and_text_embeddings[0][0])  # Get the first embedding's size\n",
    "\n",
    "        # Pad or truncate embeddings if necessary\n",
    "        pages_and_text_embeddings = [\n",
    "            [np.pad(chunk, (0, max(0, embedding_dim - len(chunk))), mode='constant')[:embedding_dim]\n",
    "             for chunk in page]\n",
    "            for page in pages_and_text_embeddings\n",
    "        ]\n",
    "\n",
    "    # Flatten nested list\n",
    "    flat_embeddings = [chunk for page in pages_and_text_embeddings for chunk in page]\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    pages_and_text_embeddings = np.array(flat_embeddings, dtype=np.float32)\n",
    "\n",
    "    # Convert to a PyTorch tensor\n",
    "    pages_and_text_embeddings = torch.tensor(pages_and_text_embeddings, dtype=torch.float32)\n",
    "    print(f\"LENGTH OF PAGES_AND_TEXT_EMBEDDINGS: {len(pages_and_text_embeddings)} AFTER\")\n",
    "    return pages_and_text_embeddings"
   ],
   "id": "f040c116297c5a9f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Getting the similarity scores using dot product between the query and the document embeddings",
   "id": "6bf58e56f31860b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:28.080309Z",
     "start_time": "2025-02-09T04:33:28.076675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_similarity_score_by_query(query: str, pages_and_text_embeddings: list[list[float]]) -> list[dict]:\n",
    "\n",
    "    '''\n",
    "    :param query:\n",
    "    :param pages_and_text_embeddings:\n",
    "    :return:\n",
    "\n",
    "    This function takes in the query and the embedding of the document as returns the similarity score between the query and the pages of the documents.\n",
    "    '''\n",
    "\n",
    "    # Initializing the embedding model for converting the query to numbers\n",
    "    embedding_model = SentenceTransformer(model_name_or_path=EMBEDDING_MODEL)\n",
    "\n",
    "    # Converting the query to numbers using the embedding model\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=True).to(\"cpu\")\n",
    "\n",
    "    # Finding the dot scores between the query embeddings and the document embeddings\n",
    "    dot_score = util.dot_score(query_embedding, pages_and_text_embeddings)[0]\n",
    "\n",
    "    # Return\n",
    "    return dot_score"
   ],
   "id": "7093f20a3ec8aeb5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Getting the top k similarity scores",
   "id": "540f27fdc861375"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:29.147566Z",
     "start_time": "2025-02-09T04:33:29.137752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_k_similarity_scores(dot_scores: list[float], k: int):\n",
    "\n",
    "    '''\n",
    "    :param dot_scores:\n",
    "    :param k:\n",
    "    :return:\n",
    "\n",
    "    Function that returns the top k similarity scores.\n",
    "    '''\n",
    "\n",
    "    # Return the top k similarity scores\n",
    "    return torch.topk(dot_scores, k=k)"
   ],
   "id": "2dc4b21b445a149b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Getting the items having the top k similarity scores",
   "id": "54dbe3248a3e9c2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:30.176478Z",
     "start_time": "2025-02-09T04:33:30.171724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_k_similar_data(dot_scores, pages_and_text):\n",
    "\n",
    "    '''\n",
    "    :param dot_scores:\n",
    "    :param pages_and_text:\n",
    "    :return:\n",
    "\n",
    "    The function fetches the pages that have the highest similarity scores.\n",
    "    '''\n",
    "\n",
    "    context = list()\n",
    "    for index in dot_scores[1]:\n",
    "        print(f\"Fetching data from page number: {index.item()}\")\n",
    "        context.append(pages_and_text[index.item()//SENTENCE_CHUNK_SIZE][\"formatted_text\"])\n",
    "    return context"
   ],
   "id": "22b574793d0a809d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Augmentation",
   "id": "7ebd2875d6f4de8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:31.255628Z",
     "start_time": "2025-02-09T04:33:31.250528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hugging_face_login():\n",
    "\n",
    "    '''\n",
    "    :return:\n",
    "\n",
    "    This model is used to log in to huggingface.co.\n",
    "    '''\n",
    "\n",
    "    from huggingface_hub import notebook_login\n",
    "    notebook_login()"
   ],
   "id": "5e958151a6053a57",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loading the LLM model for augmentation",
   "id": "8460671c24e044b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:32.500445Z",
     "start_time": "2025-02-09T04:33:32.497630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_llm_model(model_name: str):\n",
    "\n",
    "    '''\n",
    "    :param model_name:\n",
    "    :return:\n",
    "\n",
    "    This function takes in the name of the model and loads it into a model instance.\n",
    "    '''\n",
    "\n",
    "    # Load the model from the transformers (HuggingFace)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=False,\n",
    "    )\n",
    "\n",
    "    # Return\n",
    "    return model"
   ],
   "id": "74d382193f0dbd7f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Getting the model information",
   "id": "342172be64354f30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:33.545613Z",
     "start_time": "2025-02-09T04:33:33.537483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model_info(model):\n",
    "\n",
    "    '''\n",
    "    :param model:\n",
    "    :return:\n",
    "\n",
    "    This model takes in a model instance and returns a dictionary containing information about the model.\n",
    "    '''\n",
    "\n",
    "    model_information = dict()\n",
    "    try:\n",
    "        model_information[\"model_name\"] = LLM_MODEL_NAME\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"vocab_size\"] = model.config.vocab_size\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"max_position_embeddings\"] = model.config.max_position_embeddings\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"num_hidden_layers\"] = model.config.num_hidden_layers\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"num_attention_heads\"] = model.config.num_attention_heads\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"hidden_size\"] = model.config.hidden_size\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"num_labels\"] = model.config.num_labels\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"num_key_value_heads\"] = model.config.num_key_value_heads\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"layer_norm_eps\"] = model.config.layer_norm_eps\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        mem_params = sum([param.nelement() for param in model.parameters()])\n",
    "        mem_buffers = sum([buf.nelement() for buf in model.buffers()])\n",
    "        model_mem_bytes = mem_params + mem_buffers\n",
    "        model_information[\"model_memory_bytes\"] = model_mem_bytes\n",
    "        model_information[\"model_memory_in_megabytes\"] = model_mem_bytes / (1024 * 1024)\n",
    "        model_information[\"model_memory_in_gigabytes\"] = model_mem_bytes / (1024 * 1024 * 1024)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        model_information[\"number_of_parameters\"] = sum([param.numel() for param in model.parameters()])\n",
    "    except:\n",
    "        pass\n",
    "    return model_information"
   ],
   "id": "36250ac7461bad05",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Augmenting the prompt for instructing the LLM in a better way",
   "id": "168c0af9437e3e27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:34.833676Z",
     "start_time": "2025-02-09T04:33:34.827973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prompt_formatter(query: str, related_pages_and_text: list[str], llm_model_name) -> str:\n",
    "\n",
    "    '''\n",
    "    :param query:\n",
    "    :param related_pages_and_text:\n",
    "    :param llm_model_name:\n",
    "    :return:\n",
    "\n",
    "    This function is responsible for formatting the query into a prompt for the LLM, this prompt will consist of:\n",
    "    1. Format the LLM will answer in\n",
    "    2. Context using which the LLM will answer the query\n",
    "    3. Query\n",
    "    '''\n",
    "\n",
    "    # Initializing the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "\n",
    "    # Joining all the similar content into a single paragraph\n",
    "    context = \"\\n -\".join(related_pages_and_text)\n",
    "\n",
    "    # Creating a prompt format in which the data will be filled\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query\n",
    "    Context items:\n",
    "    {context}\n",
    "    Query: {query}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    # Augmenting the base prompt to create the final prompt that would be passed to the LLM\n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Creating the dialogue template\n",
    "    dialogue_template = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": base_prompt\n",
    "    }]\n",
    "\n",
    "    # Applying the prompt to the dialogue template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                           tokenize=False,\n",
    "                                           add_generation_prompt=True)\n",
    "\n",
    "    # Return\n",
    "    return prompt"
   ],
   "id": "7af51684b0a92e27",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Providing the prompt and retrieving the answer from it",
   "id": "e03de51ab8f8b3a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:33:35.900423Z",
     "start_time": "2025-02-09T04:33:35.896445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ask_question(prompt: str, llm_model, llm_model_name, temperature: int=0.4, do_sample: bool=True, max_new_tokens: int=256):\n",
    "\n",
    "    '''\n",
    "    :param prompt:\n",
    "    :param llm_model:\n",
    "    :param llm_model_name:\n",
    "    :param temperature:\n",
    "    :param do_sample:\n",
    "    :param max_new_tokens:\n",
    "    :return:\n",
    "\n",
    "    This function is responsible for asking the question using the LLM and returning the answer after the augmentation based on the similar context.\n",
    "    '''\n",
    "\n",
    "    # Initializing the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "\n",
    "    # Fetching the mapping from the tokenizer in PyTorch tensor format\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generating the output by passing in the prompt and context alongside various other parameters to the LLM model\n",
    "    outputs = llm_model.generate(**input_ids, temperature=temperature, do_sample=do_sample, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    # Decoding the encoded (embedded) output\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    # Return\n",
    "    return output_text"
   ],
   "id": "6ff6c19a32b58c98",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PROJECT FLOW",
   "id": "df6e83da28dce3a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T04:39:21.906449Z",
     "start_time": "2025-02-09T04:33:39.997320Z"
    }
   },
   "cell_type": "code",
   "source": "pages_and_text = open_and_read_pdf(pdf_path=PDF_PATH)",
   "id": "63429c736d19c81",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/105 [00:00<?, ?it/s]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\u001B[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.38it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.21it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.51it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.95it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.93it/s]\n",
      "C:\\Users\\tanay\\AppData\\Local\\Temp\\ipykernel_25616\\639846558.py:42: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  sentence_embeddings = [np.array(emb) for emb in sentence_embeddings]\n",
      "  1%|          | 1/105 [00:09<16:04,  9.28s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 110.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 108.78it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.90it/s]\n",
      "  2%|▏         | 2/105 [00:12<09:53,  5.76s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.20it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.88it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.32it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.81it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.43it/s]\n",
      "  3%|▎         | 3/105 [00:16<08:10,  4.81s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.06it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 108.28it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.40it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.81it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 158.28it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.75it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.54it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.84it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.82it/s]\n",
      "  4%|▍         | 4/105 [00:29<13:45,  8.17s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.81it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.95it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.29it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.21it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 119.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.27it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.88it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.59it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.13it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.31it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.08it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.98it/s]\n",
      "  5%|▍         | 5/105 [00:42<16:40, 10.00s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 154.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.69it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.35it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.40it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 108.06it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.87it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.52it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 150.32it/s]\n",
      "  6%|▌         | 6/105 [00:56<18:49, 11.41s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.78it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.26it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.03it/s]\n",
      "  7%|▋         | 7/105 [01:00<14:24,  8.82s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.87it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 148.70it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.29it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.10it/s]\n",
      "  8%|▊         | 8/105 [01:03<11:27,  7.08s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.78it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.95it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.01it/s]\n",
      "  9%|▊         | 9/105 [01:07<09:29,  5.93s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.80it/s]\n",
      " 10%|▉         | 10/105 [01:12<09:13,  5.83s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.64it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.06it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.26it/s]\n",
      " 10%|█         | 11/105 [01:17<08:20,  5.32s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.27it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.90it/s]\n",
      " 11%|█▏        | 12/105 [01:20<07:16,  4.70s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 106.27it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.08it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.65it/s]\n",
      " 12%|█▏        | 13/105 [01:23<06:33,  4.27s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.67it/s]\n",
      " 13%|█▎        | 14/105 [01:27<06:08,  4.05s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.19it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.35it/s]\n",
      " 14%|█▍        | 15/105 [01:30<05:44,  3.82s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.73it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.58it/s]\n",
      " 15%|█▌        | 16/105 [01:33<05:24,  3.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.37it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.95it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 168.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.19it/s]\n",
      " 16%|█▌        | 17/105 [01:37<05:19,  3.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.42it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 107.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.54it/s]\n",
      " 17%|█▋        | 18/105 [01:40<05:10,  3.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.75it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 133.41it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.76it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.38it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.97it/s]\n",
      " 18%|█▊        | 19/105 [01:44<05:02,  3.52s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.16it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.30it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.73it/s]\n",
      " 19%|█▉        | 20/105 [01:47<05:00,  3.54s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.59it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.64it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.25it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.49it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.21it/s]\n",
      " 20%|██        | 21/105 [01:51<04:52,  3.48s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.78it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.54it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.26it/s]\n",
      " 21%|██        | 22/105 [01:54<04:47,  3.46s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.39it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.65it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.70it/s]\n",
      " 22%|██▏       | 23/105 [01:57<04:40,  3.42s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 112.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.67it/s]\n",
      " 23%|██▎       | 24/105 [02:01<04:39,  3.45s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.35it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.17it/s]\n",
      " 24%|██▍       | 25/105 [02:04<04:34,  3.43s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.87it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.21it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.31it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 112.73it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.14it/s]\n",
      " 25%|██▍       | 26/105 [02:08<04:47,  3.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.22it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.42it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 110.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.49it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.23it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.91it/s]\n",
      " 26%|██▌       | 27/105 [02:13<05:00,  3.85s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.74it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.14it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.58it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.73it/s]\n",
      " 27%|██▋       | 28/105 [02:17<05:15,  4.09s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.08it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.28it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.27it/s]\n",
      " 28%|██▊       | 29/105 [02:22<05:15,  4.15s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 140.71it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 104.06it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 115.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.07it/s]\n",
      " 29%|██▊       | 30/105 [02:26<05:20,  4.28s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.23it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.54it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.93it/s]\n",
      " 30%|██▉       | 31/105 [02:30<05:03,  4.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.19it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 120.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 136.86it/s]\n",
      " 30%|███       | 32/105 [02:36<05:35,  4.59s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.39it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.49it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.54it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.96it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.68it/s]\n",
      " 31%|███▏      | 33/105 [02:40<05:21,  4.47s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 118.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.75it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.95it/s]\n",
      " 32%|███▏      | 34/105 [02:51<07:40,  6.48s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.19it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 123.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.29it/s]\n",
      " 33%|███▎      | 35/105 [02:57<07:17,  6.25s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.23it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.26it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.20it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.86it/s]\n",
      " 34%|███▍      | 36/105 [03:04<07:25,  6.46s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.05it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.76it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.69it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.35it/s]\n",
      " 35%|███▌      | 37/105 [03:07<06:21,  5.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.94it/s]\n",
      " 36%|███▌      | 38/105 [03:12<05:50,  5.23s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.85it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.07it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.59it/s]\n",
      " 37%|███▋      | 39/105 [03:16<05:36,  5.10s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.62it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.09it/s]\n",
      " 38%|███▊      | 40/105 [03:22<05:33,  5.13s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 110.23it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 121.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.25it/s]\n",
      " 39%|███▉      | 41/105 [03:25<05:05,  4.77s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.19it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.22it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.87it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.05it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.49it/s]\n",
      " 40%|████      | 42/105 [03:30<05:02,  4.81s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.18it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.63it/s]\n",
      " 41%|████      | 43/105 [03:35<04:50,  4.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.96it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.04it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.37it/s]\n",
      " 42%|████▏     | 44/105 [03:39<04:32,  4.47s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.08it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.40it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.85it/s]\n",
      " 43%|████▎     | 45/105 [03:42<04:08,  4.14s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 101.61it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.70it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.88it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.94it/s]\n",
      " 44%|████▍     | 46/105 [03:46<03:51,  3.93s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.65it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.53it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.73it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.41it/s]\n",
      " 45%|████▍     | 47/105 [03:49<03:37,  3.75s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.62it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.65it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.34it/s]\n",
      " 46%|████▌     | 48/105 [03:53<03:38,  3.84s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.86it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.70it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.75it/s]\n",
      " 47%|████▋     | 49/105 [03:56<03:27,  3.70s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.31it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.31it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.17it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.18it/s]\n",
      " 48%|████▊     | 50/105 [04:00<03:18,  3.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.07it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.88it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.52it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.86it/s]\n",
      " 49%|████▊     | 51/105 [04:03<03:10,  3.53s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.38it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.01it/s]\n",
      " 50%|████▉     | 52/105 [04:07<03:06,  3.51s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.52it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 70.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.24it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.69it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.09it/s]\n",
      " 50%|█████     | 53/105 [04:12<03:28,  4.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.40it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.26it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.53it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.72it/s]\n",
      " 51%|█████▏    | 54/105 [04:15<03:17,  3.88s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 103.16it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.06it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.67it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.65it/s]\n",
      " 52%|█████▏    | 55/105 [04:19<03:07,  3.74s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.28it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.75it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.37it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 92.95it/s]\n",
      " 53%|█████▎    | 56/105 [04:23<03:06,  3.81s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.79it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.19it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.37it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.16it/s]\n",
      " 54%|█████▍    | 57/105 [04:26<02:57,  3.70s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.31it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.54it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.08it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.18it/s]\n",
      " 55%|█████▌    | 58/105 [04:30<02:52,  3.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 107.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.07it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 109.84it/s]\n",
      " 56%|█████▌    | 59/105 [04:33<02:45,  3.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.26it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.53it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.01it/s]\n",
      " 57%|█████▋    | 60/105 [04:36<02:38,  3.52s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.33it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.62it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.64it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.64it/s]\n",
      " 58%|█████▊    | 61/105 [04:40<02:33,  3.49s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.30it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.39it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.12it/s]\n",
      " 59%|█████▉    | 62/105 [04:44<02:34,  3.59s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.26it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.31it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 63.42it/s]\n",
      " 60%|██████    | 63/105 [04:48<02:38,  3.76s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.29it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.42it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.14it/s]\n",
      " 61%|██████    | 64/105 [04:51<02:29,  3.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.84it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.74it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 79.84it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.79it/s]\n",
      " 62%|██████▏   | 65/105 [04:55<02:23,  3.58s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 87.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.38it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.21it/s]\n",
      " 63%|██████▎   | 66/105 [04:58<02:20,  3.60s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.59it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.24it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 78.88it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.67it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.46it/s]\n",
      " 64%|██████▍   | 67/105 [05:02<02:19,  3.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.19it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.37it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.24it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.83it/s]\n",
      " 65%|██████▍   | 68/105 [05:06<02:18,  3.73s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 72.22it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 94.76it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.36it/s]\n",
      " 66%|██████▌   | 69/105 [05:10<02:17,  3.82s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.70it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.64it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.85it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.66it/s]\n",
      " 67%|██████▋   | 70/105 [05:14<02:12,  3.80s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.70it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.65it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.35it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.99it/s]\n",
      " 68%|██████▊   | 71/105 [05:17<02:07,  3.75s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.79it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 80.58it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 96.64it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 102.78it/s]\n",
      " 69%|██████▊   | 72/105 [05:21<02:02,  3.70s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 133.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.38it/s]\n",
      " 70%|██████▉   | 73/105 [05:25<02:02,  3.82s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.80it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.80it/s]\n",
      " 70%|███████   | 74/105 [05:29<01:58,  3.81s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 60.14it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.21it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.28it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 54.48it/s]\n",
      " 71%|███████▏  | 75/105 [05:33<01:57,  3.92s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.61it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 73.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 77.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.94it/s]\n",
      " 72%|███████▏  | 76/105 [05:40<02:10,  4.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pages_and_text \u001B[38;5;241m=\u001B[39m \u001B[43mopen_and_read_pdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpdf_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPDF_PATH\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[10], line 39\u001B[0m, in \u001B[0;36mopen_and_read_pdf\u001B[1;34m(pdf_path)\u001B[0m\n\u001B[0;32m     36\u001B[0m sentence_chunks \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(chunk) \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m sentence_chunks]\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Generate embeddings for sentence chunks (Assuming `sentence_embedder` is defined)\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m sentence_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43msentence_embedder\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence_chunks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Ensure embeddings are NumPy arrays\u001B[39;00m\n\u001B[0;32m     42\u001B[0m sentence_embeddings \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39marray(emb) \u001B[38;5;28;01mfor\u001B[39;00m emb \u001B[38;5;129;01min\u001B[39;00m sentence_embeddings]\n",
      "Cell \u001B[1;32mIn[9], line 12\u001B[0m, in \u001B[0;36msentence_embedder\u001B[1;34m(sentences)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msentence_embedder\u001B[39m(sentences: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[0;32m      3\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m    :param sentences:\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m    :return:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03m    The function iterates over the sentence chunks, then converts each sentence chunk to an embedding and returns a list of embeddings for each sentence.\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m     embedding_model \u001B[38;5;241m=\u001B[39m \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEMBEDDING_MODEL\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m()\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m sentence \u001B[38;5;129;01min\u001B[39;00m sentences:\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:308\u001B[0m, in \u001B[0;36mSentenceTransformer.__init__\u001B[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001B[0m\n\u001B[0;32m    299\u001B[0m         model_name_or_path \u001B[38;5;241m=\u001B[39m __MODEL_HUB_ORGANIZATION__ \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m model_name_or_path\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_sentence_transformer_model(\n\u001B[0;32m    302\u001B[0m     model_name_or_path,\n\u001B[0;32m    303\u001B[0m     token,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    306\u001B[0m     local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m    307\u001B[0m ):\n\u001B[1;32m--> 308\u001B[0m     modules, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodule_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_sbert_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    320\u001B[0m     modules \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_auto_model(\n\u001B[0;32m    321\u001B[0m         model_name_or_path,\n\u001B[0;32m    322\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    329\u001B[0m         config_kwargs\u001B[38;5;241m=\u001B[39mconfig_kwargs,\n\u001B[0;32m    330\u001B[0m     )\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1767\u001B[0m, in \u001B[0;36mSentenceTransformer._load_sbert_model\u001B[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001B[0m\n\u001B[0;32m   1765\u001B[0m             revision \u001B[38;5;241m=\u001B[39m revision_path_part\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m local_files_only:\n\u001B[1;32m-> 1767\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_card_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_base_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1768\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m modules, module_kwargs\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\sentence_transformers\\model_card.py:736\u001B[0m, in \u001B[0;36mSentenceTransformerModelCardData.set_base_model\u001B[1;34m(self, model_id, revision)\u001B[0m\n\u001B[0;32m    734\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mset_base_model\u001B[39m(\u001B[38;5;28mself\u001B[39m, model_id: \u001B[38;5;28mstr\u001B[39m, revision: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    735\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 736\u001B[0m         model_info \u001B[38;5;241m=\u001B[39m \u001B[43mget_model_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    737\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    738\u001B[0m         \u001B[38;5;66;03m# Getting the model info can fail for many reasons: model does not exist, no internet, outage, etc.\u001B[39;00m\n\u001B[0;32m    739\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[0;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:2488\u001B[0m, in \u001B[0;36mHfApi.model_info\u001B[1;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, expand, token)\u001B[0m\n\u001B[0;32m   2486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m expand:\n\u001B[0;32m   2487\u001B[0m     params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpand\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m expand\n\u001B[1;32m-> 2488\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43mget_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2489\u001B[0m hf_raise_for_status(r)\n\u001B[0;32m   2490\u001B[0m data \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mjson()\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\requests\\sessions.py:602\u001B[0m, in \u001B[0;36mSession.get\u001B[1;34m(self, url, **kwargs)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001B[39;00m\n\u001B[0;32m    595\u001B[0m \n\u001B[0;32m    596\u001B[0m \u001B[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001B[39;00m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;124;03m:rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    599\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    601\u001B[0m kwargs\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 602\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    587\u001B[0m }\n\u001B[0;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:93\u001B[0m, in \u001B[0;36mUniqueRequestIdAdapter.send\u001B[1;34m(self, request, *args, **kwargs)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mRequestException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     95\u001B[0m     request_id \u001B[38;5;241m=\u001B[39m request\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[0;32m    784\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[1;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    800\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[0;32m    803\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 534\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[1;32mD:\\AIML\\.venv\\Lib\\site-packages\\urllib3\\connection.py:516\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    513\u001B[0m _shutdown \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshutdown\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    515\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[1;32m--> 516\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    519\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[1;32mD:\\IDLE\\Lib\\http\\client.py:1430\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1428\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1429\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1430\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m   1432\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mD:\\IDLE\\Lib\\http\\client.py:331\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 331\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[0;32m    333\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32mD:\\IDLE\\Lib\\http\\client.py:292\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 292\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[0;32m    294\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\IDLE\\Lib\\socket.py:720\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    718\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    719\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 720\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    721\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    722\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\IDLE\\Lib\\ssl.py:1251\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1247\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1248\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1249\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1250\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32mD:\\IDLE\\Lib\\ssl.py:1103\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1101\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1102\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1103\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1104\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1105\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_embeddings = get_data_embeddings(pages_and_text=pages_and_text)",
   "id": "e15c3d571727fdcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = QUERY\n",
    "dot_scores = get_similarity_score_by_query(query=query, pages_and_text_embeddings=data_embeddings)"
   ],
   "id": "5522bfffa66f6cf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k = K\n",
    "top_k_similarity_scores = get_top_k_similarity_scores(dot_scores=dot_scores, k=k)"
   ],
   "id": "a0754ea1880d5378",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "similar_top_k_context = get_top_k_similar_data(top_k_similarity_scores, pages_and_text)",
   "id": "279d34c8a6d3330e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hugging_face_login()",
   "id": "ec4530c7481f61fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_model = load_llm_model(model_name=LLM_MODEL_NAME)",
   "id": "afb7c9ae2f704df5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_model_info(llm_model)",
   "id": "21fea257adeba501",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt = prompt_formatter(QUERY, similar_top_k_context, LLM_MODEL_NAME)\n",
    "print(prompt)"
   ],
   "id": "51bab0da0faf8960",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ask_question(prompt, llm_model, LLM_MODEL_NAME)",
   "id": "7c7590f1895eb29",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
